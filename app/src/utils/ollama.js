const { BrowserWindow, ipcMain } = require('electron');
const { getSystemPrompt } = require('./prompts');

let currentSessionId = null;
let conversationHistory = [];
let isInitializingSession = false;
let ollamaModel = 'deepseek-coder:6.7b';
let visionModel = 'llava:7b';
let ollamaUrl = 'http://localhost:11434';
let serverUrl = process.env.SERVER_URL || 'http://localhost:3000';
let systemPrompt = '';

function sendToRenderer(channel, data) {
    const windows = BrowserWindow.getAllWindows();
    if (windows.length > 0) {
        windows[0].webContents.send(channel, data);
    }
}

function initializeNewSession() {
    currentSessionId = Date.now().toString();
    conversationHistory = [];
    console.log({ sessionId: currentSessionId });
}

function saveConversationTurn(userMessage, aiResponse, imageProcessed = false) {
    if (!currentSessionId) {
        initializeNewSession();
    }

    const conversationTurn = {
        timestamp: Date.now(),
        transcription: userMessage.trim(),
        ai_response: aiResponse.trim(),
        has_image: imageProcessed,
    };

    conversationHistory.push(conversationTurn);
    console.log({ conversationTurn });

    sendToRenderer('save-conversation-turn', {
        sessionId: currentSessionId,
        turn: conversationTurn,
        fullHistory: conversationHistory,
    });
}

function getCurrentSessionData() {
    return {
        sessionId: currentSessionId,
        history: conversationHistory,
    };
}

async function checkOllamaAvailability() {
    try {
        const response = await fetch(`${ollamaUrl}/api/tags`, {
            method: 'GET',
            headers: {
                'Content-Type': 'application/json',
            },
        });

        if (!response.ok) {
            return { available: false, error: `Ollama server returned status ${response.status}` };
        }

        const data = await response.json();
        const models = data.models || [];
        const hasModel = models.some(m => m.name === ollamaModel || m.name.startsWith(ollamaModel.split(':')[0]));
        const hasVisionModel = models.some(m => m.name.includes('llava') || m.name.includes('bakllava'));

        return {
            available: true,
            models: models.map(m => m.name),
            hasModel,
            hasVisionModel,
        };
    } catch (error) {
        return {
            available: false,
            error: error.message,
        };
    }
}

async function initializeOllamaSession(customPrompt = '', profile = 'leetcode', model = 'deepseek-coder:6.7b') {
    if (isInitializingSession) {
        console.log({ message: 'Session initialization already in progress' });
        return false;
    }

    isInitializingSession = true;
    sendToRenderer('session-initializing', true);

    try {
        ollamaModel = model;
        systemPrompt = getSystemPrompt(profile, customPrompt, false);

        const checkResult = await checkOllamaAvailability();
        if (!checkResult.available) {
            throw new Error(`Ollama server is not available at ${ollamaUrl}. Please make sure Ollama is running: ollama serve`);
        }

        if (!checkResult.hasModel) {
            console.warn({ message: `Model ${ollamaModel} not found. Available models: ${checkResult.models.join(', ')}` });
            sendToRenderer('update-status', `Warning: Model ${ollamaModel} not found. Using available model.`);
        }

        if (!checkResult.hasVisionModel) {
            sendToRenderer('update-status', `âš ï¸  Ð”Ð»Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ ÑÐºÐ°Ñ‡Ð°Ð¹Ñ‚Ðµ: ollama pull llava:7b`);
        }

        initializeNewSession();

        isInitializingSession = false;
        sendToRenderer('session-initializing', false);
        sendToRenderer('update-status', 'Ollama connected');
        sendToRenderer('model-info', {
            codeModel: ollamaModel,
            visionModel: visionModel,
            hasVision: checkResult.hasVisionModel,
        });
        return true;
    } catch (error) {
        console.error({ error: error.message });
        isInitializingSession = false;
        sendToRenderer('session-initializing', false);
        sendToRenderer('update-status', 'Error: ' + error.message);
        return false;
    }
}

async function analyzeImageWithVision(imageBase64, question) {
    try {
        const cleanBase64 = imageBase64.replace(/^data:image\/\w+;base64,/, '');
        
        console.log({ message: 'ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...' });
        sendToRenderer('update-status', 'ðŸ” ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ...');

        const response = await fetch(`${ollamaUrl}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: visionModel,
                prompt: (question || 'Ð§Ñ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¾ Ð½Ð° ÑÑ‚Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐµ? ÐžÐ¿Ð¸ÑˆÐ¸ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚Ð°.') + ' ÐžÐ¢Ð’Ð•Ð§ÐÐ™ ÐÐ Ð Ð£Ð¡Ð¡ÐšÐžÐœ Ð¯Ð—Ð«ÐšÐ•.',
                images: [cleanBase64],
                stream: false,
                options: {
                    temperature: 0.1,
                    num_predict: 1000,
                },
            }),
        });

        if (!response.ok) {
            throw new Error(`Vision error: ${response.status}`);
        }

        const data = await response.json();
        console.log({ message: 'Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾' });
        return data.response;
    } catch (error) {
        console.error({ error: error.message });
        throw error;
    }
}

async function solveAlgorithmFromImage(imageBase64, userQuestion = '') {
    try {
        sendToRenderer('update-status', 'ðŸ“¸ ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€...');
        
        const response = await fetch(`${serverUrl}/api/image`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                imageData: imageBase64,
                question: userQuestion || '',
            }),
        });

        if (!response.ok) {
            const errorText = await response.text();
            let errorMessage = `Server error: ${response.status}`;
            try {
                const errorJson = JSON.parse(errorText);
                if (errorJson.error) {
                    errorMessage = errorJson.error;
                }
            } catch (e) {
                errorMessage = errorText || errorMessage;
            }
            throw new Error(errorMessage);
        }

        const result = await response.json();
        
        if (!result.success) {
            throw new Error(result.error || 'Failed to solve problem');
        }

        if (result.response) {
            const fullResponse = result.response;
            sendToRenderer('update-response', fullResponse);

            const userMessageText = userQuestion || 'Ð ÐµÑˆÐ¸ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ';
            saveConversationTurn(userMessageText, fullResponse, true);
            
            sendToRenderer('update-status', 'âœ… Ð—Ð°Ð´Ð°Ñ‡Ð° Ñ€ÐµÑˆÐµÐ½Ð°!');
            return { success: true, response: fullResponse };
        }

        throw new Error('No response from server');
    } catch (error) {
        console.error({ error: error.message });
        sendToRenderer('update-status', `âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: ${error.message}`);
        return { success: false, error: error.message };
    }
}

async function sendMessage(text, imageBase64 = null) {
    if (!currentSessionId) {
        await initializeOllamaSession('', 'leetcode');
    }

    try {
        if (imageBase64) {
            return await solveAlgorithmFromImage(imageBase64, text);
        }

        if (!text || text.trim().length === 0) {
            return { success: false, error: 'Empty message' };
        }
        const messages = [];

        if (systemPrompt) {
            messages.push({
                role: 'system',
                content: systemPrompt,
            });
        }

        for (const turn of conversationHistory) {
            messages.push({
                role: 'user',
                content: turn.transcription,
            });
            messages.push({
                role: 'assistant',
                content: turn.ai_response,
            });
        }

        messages.push({
            role: 'user',
            content: `Ð’ÐÐ–ÐÐž: 
- ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð° JavaScript. ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Python Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ¸.
- ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (regexp) Ð² Ñ€ÐµÑˆÐµÐ½Ð¸Ð¸, ÐµÑÐ»Ð¸ Ð¾Ð± ÑÑ‚Ð¾Ð¼ ÑÐ²Ð½Ð¾ Ð½Ðµ Ð¿Ñ€Ð¾ÑÑÑ‚. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹.
- ÐžÐ¢Ð’Ð•Ð§ÐÐ™ ÐÐ Ð Ð£Ð¡Ð¡ÐšÐžÐœ Ð¯Ð—Ð«ÐšÐ•.
- ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž: Ð’Ð¡Ð•Ð“Ð”Ð Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ð² ÐºÐ¾Ð´ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ. ÐšÐÐ–Ð”ÐÐ¯ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ‡Ð°ÑÑ‚ÑŒ ÐºÐ¾Ð´Ð° (Ñ†Ð¸ÐºÐ»Ñ‹, ÑƒÑÐ»Ð¾Ð²Ð¸Ñ, Ð¿Ñ€Ð¸ÑÐ²Ð°Ð¸Ð²Ð°Ð½Ð¸Ñ, Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ñ‹ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹) Ð”ÐžÐ›Ð–ÐÐ Ð¸Ð¼ÐµÑ‚ÑŒ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹, Ð¾Ð±ÑŠÑÑÐ½ÑÑŽÑ‰Ð¸Ð¹ Ñ‡Ñ‚Ð¾ Ð¾Ð½Ð° Ð´ÐµÐ»Ð°ÐµÑ‚ Ð¸ Ð·Ð°Ñ‡ÐµÐ¼. Ð‘ÐµÐ· ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² ÐºÐ¾Ð´ ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð½ÐµÐ¿Ð¾Ð»Ð½Ñ‹Ð¼ Ð¸ Ð½ÐµÐ²ÐµÑ€Ð½Ñ‹Ð¼.
- Ð’ ÐÐÐ§ÐÐ›Ð• Ð¾Ñ‚Ð²ÐµÑ‚Ð° ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð½Ð°Ð¿Ð¸ÑˆÐ¸: "Ð”Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ ÑÑ‚Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¼Ñ‹ Ð±ÑƒÐ´ÐµÐ¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ [Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ¸/Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð°], ..." Ð¸ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ Ð¾Ð±ÑŠÑÑÐ½Ð¸ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ð¸ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÑŽ.

${text}`,
        });

        sendToRenderer('update-status', 'Processing...');

        const response = await fetch(`${ollamaUrl}/api/chat`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                model: ollamaModel,
                messages: messages,
                stream: true,
                options: {
                    temperature: 0.1,
                },
            }),
        });

        if (!response.ok) {
            const errorText = await response.text();
            let errorMessage = `HTTP error! status: ${response.status}`;

            try {
                const errorJson = JSON.parse(errorText);
                if (errorJson.error) {
                    errorMessage = errorJson.error;
                }
            } catch (e) {
                errorMessage = errorText || errorMessage;
            }

            if (response.status === 404) {
                errorMessage = `Model ${ollamaModel} not found. Please pull it: ollama pull ${ollamaModel}`;
            } else if (response.status === 0 || response.status >= 500) {
                errorMessage = `Ollama server is not available. Please make sure Ollama is running: ollama serve`;
            }

            throw new Error(errorMessage);
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let fullResponse = '';
        let buffer = '';

        while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || '';

            for (const line of lines) {
                if (line.trim() === '') continue;

                try {
                    const json = JSON.parse(line);
                    const content = json.message?.content || json.content || '';
                    if (content) {
                        fullResponse += content;
                        sendToRenderer('update-response', fullResponse);
                    }

                    if (json.done) {
                        break;
                    }
                } catch (e) {
                    console.error({ error: 'Failed to parse Ollama response', line, parseError: e.message });
                }
            }
        }

        if (buffer.trim()) {
            try {
                const json = JSON.parse(buffer);
                const content = json.message?.content || json.content || '';
                if (content) {
                    fullResponse += content;
                    sendToRenderer('update-response', fullResponse);
                }
            } catch (e) {
                console.error({ error: 'Failed to parse final Ollama response', buffer, parseError: e.message });
            }
        }

        if (text && fullResponse) {
            saveConversationTurn(text, fullResponse, false);
        }

        sendToRenderer('update-status', 'Ready');
        return { success: true };
    } catch (error) {
        console.error({ error: error.message });
        sendToRenderer('update-status', 'Error: ' + error.message);
        return { success: false, error: error.message };
    }
}

function setupOllamaIpcHandlers() {
    ipcMain.handle('initialize-gemini', async (event, apiKey, customPrompt, profile = 'leetcode', language = 'en-US') => {
        const model = apiKey || 'deepseek-coder:6.7b';
        const success = await initializeOllamaSession(customPrompt, profile, model);
        return success;
    });

    ipcMain.handle('send-text-message', async (event, text) => {
        if (!text || typeof text !== 'string' || text.trim().length === 0) {
            return { success: false, error: 'Invalid text message' };
        }

        console.log({ text });
        return await sendMessage(text.trim(), null);
    });

    ipcMain.handle('send-image-content', async (event, { data, question }) => {
        console.log({ message: 'ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ', size: data?.length || 0 });
        
        if (!data || typeof data !== 'string') {
            return { success: false, error: 'Invalid image data' };
        }
        
        const imageDataUrl = `data:image/jpeg;base64,${data}`;
        
        return await solveAlgorithmFromImage(imageDataUrl, question || '');
    });

    ipcMain.handle('close-session', async event => {
        try {
            ollamaModel = 'deepseek-coder:6.7b';
            visionModel = 'llava:7b';
            systemPrompt = '';
            sendToRenderer('update-status', 'Session closed');
            return { success: true };
        } catch (error) {
            console.error({ error: error.message });
            return { success: false, error: error.message };
        }
    });

    ipcMain.handle('get-current-session', async event => {
        try {
            return {
                success: true,
                data: {
                    ...getCurrentSessionData(),
                    codeModel: ollamaModel,
                    visionModel: visionModel,
                },
            };
        } catch (error) {
            console.error({ error: error.message });
            return { success: false, error: error.message };
        }
    });

    ipcMain.handle('start-new-session', async event => {
        try {
            initializeNewSession();
            return { success: true, sessionId: currentSessionId };
        } catch (error) {
            console.error({ error: error.message });
            return { success: false, error: error.message };
        }
    });

    ipcMain.handle('check-ollama', async event => {
        try {
            return { success: true, data: await checkOllamaAvailability() };
        } catch (error) {
            console.error({ error: error.message });
            return { success: false, error: error.message };
        }
    });
}

module.exports = {
    initializeOllamaSession,
    sendToRenderer,
    initializeNewSession,
    saveConversationTurn,
    getCurrentSessionData,
    setupOllamaIpcHandlers,
    checkOllamaAvailability,
    analyzeImageWithVision,
    solveAlgorithmFromImage,
};
